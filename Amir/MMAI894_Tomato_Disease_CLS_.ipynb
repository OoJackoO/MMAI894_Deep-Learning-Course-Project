{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "ElSmoDu2PiYt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading & Loading the Dataset"
      ],
      "metadata": {
        "id": "IUAQ4aubCBAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huUQr-u5TjX7"
      },
      "outputs": [],
      "source": [
        "# !pip install -q kaggle\n",
        "# ! mkdir ~/content/drive/My Drive/Colab Notebooks/MMAI 894\n",
        "# ! cp kaggle.json ~/content/drive/My Drive/Colab Notebooks/MMAI 894/\n",
        "# ! chmod 600 ~/kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')"
      ],
      "metadata": {
        "id": "jYk09u_GOBvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the directory to where you want to have your dataset & jason authentication file\n",
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset\"\n",
        "# %cd /content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/"
      ],
      "metadata": {
        "id": "vab1_pq12dls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "# import zipfile"
      ],
      "metadata": {
        "id": "wRkviHwaz4X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # this will prompt you to upload the kaggle.json\n",
        "# from google.colab import files\n",
        "\n",
        "# files.upload() "
      ],
      "metadata": {
        "id": "E5xsEk5c6n6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Check if your jason file is there and authentication is successful\n",
        "# api = KaggleApi()\n",
        "# api.authenticate()\n",
        "# !ls -lha kaggle.json"
      ],
      "metadata": {
        "id": "r1qTUG5p6a-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ! kaggle competitions download google-smartphone-decimeter-challenge\n",
        "# !kaggle datasets download -d cookiefinder/tomato-disease-multiple-sources\n",
        "# with zipfile.ZipFile('tomato-disease-multiple-sources.zip', 'r') as zip_ref:\n",
        "#         zip_ref.extractall('./')"
      ],
      "metadata": {
        "id": "X1oTWsRp2qHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tomato Leaf Disease"
      ],
      "metadata": {
        "id": "g5aOVPfnEP3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "from PIL import ImageFile\n",
        "\n",
        "import PIL\n",
        "import PIL.Image\n",
        "\n",
        "from pathlib import Path\n",
        "import imghdr"
      ],
      "metadata": {
        "id": "1z7McUjE9XhX"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the directory to your specific folder in Google Drive\n",
        "folder_path = \"/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/\"\n",
        "\n",
        "# Check if the directory exists and print the list of files and folders inside it\n",
        "if os.path.exists(folder_path):\n",
        "    files = os.listdir(folder_path)\n",
        "    print(files)\n",
        "else:\n",
        "    print(\"Directory does not exist.\")\n",
        "\n",
        "root_dir = \"/content/drive/My Drive/\" \n",
        "# choose where you want your project files to be saved\n",
        "project_folder = \"Colab Notebooks/MMAI 894/Dataset/\"\n",
        "os.chdir(root_dir + project_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqxH1ym3fuiw",
        "outputId": "a1896794-453d-42d4-b226-b0069a6a8a7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['tomato-disease-multiple-sources.zip', 'train', 'valid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlxUiPzph8xS",
        "outputId": "e2a9d722-b0a7-4443-d927-4b68587b0285"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = os.getcwd()\n",
        "train_dir = os.path.join(main_dir, 'train')\n",
        "val_dir = os.path.join(main_dir, 'valid')"
      ],
      "metadata": {
        "id": "7I6a7weA2Cl6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tensorflow.org/tutorials/load_data/images"
      ],
      "metadata": {
        "id": "EDHEciYs1nSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=os.listdir(train_dir),\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=24,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSZXo5RDrrPs",
        "outputId": "be93ad76-b3d5-4184-ea7b-045eebf244f3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25821 files belonging to 11 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Original_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=24,\n",
        "    validation_split=0.5,\n",
        "    subset='both',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hqH4ssHtkq1",
        "outputId": "0dd70ea5-01b3-4d3b-c752-ed22b4f977ab"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6677 files belonging to 11 classes.\n",
            "Using 3339 files for training.\n",
            "Using 3338 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = Original_val_ds[0]\n",
        "test_ds = Original_val_ds[1]"
      ],
      "metadata": {
        "id": "EHaZGVqI04l7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrBtgkStsQfT",
        "outputId": "6a82cb62-56d1-4f8f-87a8-d6517c64e58b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cvrsaN81aOn",
        "outputId": "236fd5e1-fbe5-43b8-aaa8-e6a3e12a7c02"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Bacterial_spot', 'Early_blight', 'Late_blight', 'Leaf_Mold', 'Septoria_leaf_spot', 'Spider_mites Two-spotted_spider_mite', 'Target_Spot', 'Tomato_Yellow_Leaf_Curl_Virus', 'Tomato_mosaic_virus', 'healthy', 'powdery_mildew']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/68191448/unknown-image-file-format-one-of-jpeg-png-gif-bmp-required\n",
        "\n",
        "https://www.tensorflow.org/tutorials/load_data/images\n",
        "\n",
        "https://stackoverflow.com/questions/65438156/tensorflow-keras-error-unknown-image-file-format-one-of-jpeg-png-gif-bmp-re"
      ],
      "metadata": {
        "id": "BKkwICcD37v0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Need to check if the images are properly formatted and ready to be used."
      ],
      "metadata": {
        "id": "BtqCQRM41L62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = train_dir\n",
        "image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
        "\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\", 'jpg']\n",
        "for filepath in Path(data_dir).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in image_extensions:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqcMDr8-7ah9",
        "outputId": "be385dff-de36-4425-f5b0-6b565aad603d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Early_blight/early-blight-tomato-causal-agents-260nw-1746486380.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Early_blight/EB_(976).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Early_blight/220px-Alternaria_solani_-_leaf_lesions.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Leaf_Mold/BM_(6).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Leaf_Mold/BM_(7).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Leaf_Mold/BM_(975).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Leaf_Mold/BM_(976).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Leaf_Mold/BM_(98).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Leaf_Mold/607-155-1.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/Septoria_leaf_spot/SS_ (51).jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/healthy/tomato-leaf-isolated-on-white-260nw-580281301.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/train/healthy/branch-tomato-leaves-iaolsted-on-260nw-1025727106.jpg is not an image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#JPEG, PNG, GIF, BMP\n",
        "data_dir = val_dir\n",
        "image_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n",
        "\n",
        "img_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\", 'jpg']\n",
        "for filepath in Path(data_dir).rglob(\"*\"):\n",
        "    if filepath.suffix.lower() in image_extensions:\n",
        "        img_type = imghdr.what(filepath)\n",
        "        if img_type is None:\n",
        "            print(f\"{filepath} is not an image\")\n",
        "        elif img_type not in img_type_accepted_by_tf:\n",
        "            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nsy2NLTAiEz",
        "outputId": "e851f8bb-b417-480f-a247-43ee780d536a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/valid/Leaf_Mold/607-155-0.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/valid/healthy/tomato-leaf-isolated-on-white-260nw-1167806389.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/valid/healthy/tomato-leaves-isolated-on-white-260nw-1251320371.jpg is not an image\n",
            "/content/drive/My Drive/Colab Notebooks/MMAI 894/Dataset/valid/healthy/tomato-leaves-isolated-on-white-260nw-1313938871.jpg is not an image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "          'RANDOM_STATE': 24,\n",
        "          'TRAINABLE': False,\n",
        "          'DENSE_ACTIVATION':'relu',\n",
        "          'DROPOUT_RATE':0.3,\n",
        "          'LEARNING_RATE': 5e-4,\n",
        "          'LEARNING_RATE_DECAY':False,\n",
        "          'CHECKPOINT':True,\n",
        "          'EPOCHS':100,\n",
        "}"
      ],
      "metadata": {
        "id": "AQ4OK341Bu-l"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  # tf.keras.layers.Rescaling(1./255),\n",
        "\n",
        "  tf.keras.layers.Conv2D(32, 3, activation=params['DENSE_ACTIVATION']),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Conv2D(32, 3, activation=params['DENSE_ACTIVATION']),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Conv2D(32, 3, activation=params['DENSE_ACTIVATION']),\n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(64, activation=params['DENSE_ACTIVATION']),\n",
        "\n",
        "  tf.keras.layers.Dropout(params['DROPOUT_RATE']),\n",
        "  tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "# Build the model by calling the build() method\n",
        "model.build(input_shape=(None, 224, 224, 3))"
      ],
      "metadata": {
        "id": "YpfdAqsX2IW3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rfkNc7-Atcl",
        "outputId": "da9e4d65-882e-4478-ec11-4fa2e74e0b98"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_30 (Conv2D)          (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 111, 111, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 109, 109, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 54, 54, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 52, 52, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 26, 26, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 21632)             0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 64)                1384512   \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 11)                715       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,404,619\n",
            "Trainable params: 1,404,619\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=params['LEARNING_RATE']) \n",
        "model.compile(\n",
        "  optimizer=optimizer,\n",
        "  loss=categorical_crossentropy,\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LSzNlsEL2L9D"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping \n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    mode='min',\n",
        "    restore_best_weights=True,\n",
        "    patience=7, \n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# check point - save best model\n",
        "check_point = ModelCheckpoint(filepath='../model/cnn_best_1.hdf5',\n",
        "                                          monitor='val_loss',\n",
        "                                          mode='min',\n",
        "                                          save_best_only=True\n",
        "                                          )\n",
        "\n",
        "\n",
        "# learning rate schedule\n",
        "lr_start = 0.01\n",
        "\n",
        "def exponential_decay(lr0, s):\n",
        "    def exponential_decay_fn(epoch):\n",
        "        return lr0 * 0.1 **(epoch / s)\n",
        "    return exponential_decay_fn\n",
        "\n",
        "exponential_decay_fn = exponential_decay(lr_start, params['EPOCHS'])\n",
        "lr_scheduler = LearningRateScheduler(exponential_decay_fn)\n",
        "     \n",
        "\n",
        "callbacks = [early_stopping]\n",
        "\n",
        "if params['CHECKPOINT']:\n",
        "  callbacks.append(check_point)\n",
        "if params['LEARNING_RATE_DECAY']:\n",
        "  callbacks.append(lr_scheduler)\n",
        "\n",
        "callbacks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-l7eIyxDMbO",
        "outputId": "e1c523e6-b163-4ae0-fd65-0ab0de44eedb"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.callbacks.EarlyStopping at 0x7f1b86dc9b50>,\n",
              " <tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7f1b86dc9400>]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  callbacks = callbacks,\n",
        "  epochs=params['EPOCHS']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lk6tRKM2NcI",
        "outputId": "fe0202c7-d044-406c-aa3b-31f544e2ba35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "341/807 [===========>..................] - ETA: 15:25 - loss: 4.3220 - accuracy: 0.2363"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(\"test loss: {} and test accuracy: {}\".format(test_loss, test_accuracy))"
      ],
      "metadata": {
        "id": "doztKxHsGG7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/MMAI 894/CNN.h5')"
      ],
      "metadata": {
        "id": "v5wH6MUMGWPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/drive/My Drive/Colab Notebooks/MMAI 894/CNN.h5')"
      ],
      "metadata": {
        "id": "fSXWB_c6GX3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(hist):\n",
        "  '''\n",
        "  This function plots training history. (ie training loss vs validation loss)\n",
        "  '''\n",
        "  tr_acc = hist.history['accuracy']\n",
        "  tr_loss = hist.history['loss']\n",
        "  val_acc = hist.history['val_accuracy']\n",
        "  val_loss = hist.history['val_loss']\n",
        "  index_loss = np.argmin(val_loss)\n",
        "  val_lowest = val_loss[index_loss]\n",
        "  index_acc = np.argmax(val_acc)\n",
        "  acc_highest = val_acc[index_acc]\n",
        "\n",
        "  plt.figure(figsize= (20, 8))\n",
        "  plt.style.use('fivethirtyeight')\n",
        "  Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "  loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "  acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "  plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "  plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "  plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "  plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.tight_layout\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "TbD88giRGvu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training(history)"
      ],
      "metadata": {
        "id": "zqnkYjOTGq1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = []\n",
        "for _, label in test_ds.map(lambda x, y: (x, y)):\n",
        "    test_labels.append(label.numpy())"
      ],
      "metadata": {
        "id": "q_VSfXmxGySy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "# convert labels to numerical format\n",
        "test_labels = np.concatenate([y for x, y in test_ds])\n",
        "test_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# predict on test dataset\n",
        "y_pred_cnn = model.predict(test_ds)\n",
        "\n",
        "# convert predictions to class labels\n",
        "y_pred_cnn = np.argmax(y_pred_cnn, axis=1)\n",
        "\n",
        "# print classification report\n",
        "print(classification_report(test_labels, y_pred_cnn, target_names=class_names))\n",
        "\n",
        "# create confusion matrix\n",
        "cm = confusion_matrix(test_labels, y_pred_cnn)\n",
        "\n",
        "# plot confusion matrix using heatmap\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m6kx7JLyGzsU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}